{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os\n",
    "# from model import GNNRecommender\n",
    "from util import get_node_encoder, prepare_temporal_graph_data\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNRecommender(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels=128, embedding_dim=64):\n",
    "        super(GNNRecommender, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            GATConv(num_features, hidden_channels, heads=4),\n",
    "            torch.nn.LayerNorm(hidden_channels * 4),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            GATConv(hidden_channels * 4, hidden_channels, heads=2),\n",
    "            torch.nn.LayerNorm(hidden_channels * 2),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            GATConv(hidden_channels * 2, embedding_dim),\n",
    "            torch.nn.LayerNorm(embedding_dim),\n",
    "            torch.nn.ELU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim, hidden_channels),\n",
    "            torch.nn.LayerNorm(hidden_channels),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            torch.nn.Linear(hidden_channels, num_features),\n",
    "            torch.nn.LayerNorm(num_features),\n",
    "            torch.nn.ELU()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, edge_index, edge_attr=None):\n",
    "        # 提取節點嵌入\n",
    "        for layer in self.encoder:\n",
    "            if isinstance(layer, GATConv):\n",
    "                x = layer(x, edge_index, edge_attr)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        # 解碼節點嵌入\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        # 編碼\n",
    "        embeddings = self.encode(x, edge_index, edge_attr)\n",
    "        # 解碼\n",
    "        reconstructed = self.decode(embeddings)\n",
    "        return reconstructed, embeddings\n",
    "    \n",
    "    def get_embedding(self, x, edge_index, edge_attr=None):\n",
    "        # 獲取節點嵌入\n",
    "        with torch.no_grad():\n",
    "            return self.encode(x, edge_index, edge_attr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1156it [00:33, 34.55it/s]\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 60\n",
    "REMOVED_SAME_GROUP = True\n",
    "\n",
    "# 加載數據\n",
    "collaboration_df = pd.read_csv(\"/home/bl515-ml/Documents/shaio_jie/sma/Kpop_challenge_analyze/data/collaboration_videos.csv\")\n",
    "collaboration_df['timestamp'] = collaboration_df['timestamp'].astype(float)\n",
    "\n",
    "# 只使用不同組的藝人\n",
    "if REMOVED_SAME_GROUP:\n",
    "    collaboration_df = collaboration_df[collaboration_df['source'].str.split('_').str[0] != collaboration_df['target'].str.split('_').str[0]]\n",
    "\n",
    "# 獲取節點編碼器\n",
    "node_encoder = get_node_encoder()\n",
    "\n",
    "# 只使用歷史數據\n",
    "itter = collaboration_df[collaboration_df['timestamp'] < datetime(2025, 1, 1).timestamp()]\n",
    "\n",
    "num_nodes = node_encoder.classes_.shape[0]\n",
    "x = torch.eye(num_nodes)  # 使用 one-hot 編碼作為初始特徵\n",
    "\n",
    "# 創建時序數據加載器\n",
    "snapshots = []\n",
    "for _, row in tqdm(itter.iterrows()):\n",
    "    start_time = row['timestamp'] - WINDOW_SIZE * 24 * 3600\n",
    "    # 獲取當前窗口內的數據\n",
    "    window_data = collaboration_df[\n",
    "        (collaboration_df['timestamp'] >= start_time) & \n",
    "        (collaboration_df['timestamp'] < row['timestamp'])\n",
    "    ]\n",
    "        \n",
    "    if len(window_data) > 0:\n",
    "        # 創建邊索引和特徵\n",
    "        edge_index = []\n",
    "        edge_feature = []\n",
    "            \n",
    "        for _, row in window_data.iterrows():\n",
    "            artist1_idx = node_encoder.transform([row['source']])[0]\n",
    "            artist2_idx = node_encoder.transform([row['target']])[0]\n",
    "                \n",
    "            edge_index.append([artist1_idx, artist2_idx])\n",
    "                \n",
    "            # 計算邊特徵Tuet\n",
    "            views = row['views'] if 'views' in row else 0\n",
    "            likes = row['likes'] if 'likes' in row else 0\n",
    "            comments = row['comments'] if 'comments' in row else 0\n",
    "\n",
    "            # 組合特徵\n",
    "            feature = [ views, likes, comments]\n",
    "            edge_feature.append(feature)\n",
    "            \n",
    "            \n",
    "        # 轉換為張量\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_feature = torch.tensor(edge_feature, dtype=torch.float)\n",
    "\n",
    "        # 創建圖數據\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_feature)\n",
    "        snapshots.append(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 197.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Loss: 0.3514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 227.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 227.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 227.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 226.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 224.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1151/1151 [00:05<00:00, 225.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 0.3156\n",
      "Early stopping triggered after 14 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GNNRecommender(num_features=num_nodes).to('cuda')\n",
    "num_epochs = 200\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 設定 early stopping 參數\n",
    "patience = 10\n",
    "min_delta = 0.001\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# 修改訓練循環\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for snapshot in tqdm(snapshots):\n",
    "        cuda_snapshot = snapshot.to('cuda')\n",
    "        out, embeddings = model(cuda_snapshot.x, cuda_snapshot.edge_index, cuda_snapshot.edge_attr)\n",
    "        \n",
    "        # 計算重構損失\n",
    "        reconstruction_loss = F.mse_loss(out, cuda_snapshot.x)\n",
    "        \n",
    "        # 計算嵌入的相似度損失\n",
    "        similarity_matrix = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "        \n",
    "        # 使用邊信息作為正樣本對\n",
    "        positive_pairs = cuda_snapshot.edge_index.t()\n",
    "        positive_similarities = similarity_matrix[positive_pairs[:, 0], positive_pairs[:, 1]]\n",
    "        \n",
    "        # 計算對比損失\n",
    "        contrastive_loss = -torch.mean(torch.log(torch.sigmoid(positive_similarities)))\n",
    "        \n",
    "        # 總損失\n",
    "        loss = reconstruction_loss + contrastive_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(snapshots)\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Early stopping 檢查\n",
    "    if avg_loss < best_loss - min_delta:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加載最佳模型\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [00:09, 12.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 只使用歷史數據\n",
    "test_itter = collaboration_df[collaboration_df['timestamp'] >= datetime(2025, 1, 1).timestamp()]\n",
    "\n",
    "# 創建時序數據加載器\n",
    "test_snapshots = []\n",
    "for _, row in tqdm(test_itter.iterrows()):\n",
    "    start_time = row['timestamp'] - WINDOW_SIZE * 24 * 3600\n",
    "    # 獲取當前窗口內的數據\n",
    "    window_data = collaboration_df[\n",
    "        (collaboration_df['timestamp'] >= start_time) & \n",
    "        (collaboration_df['timestamp'] < row['timestamp'])\n",
    "    ]\n",
    "        \n",
    "    if len(window_data) > 0:\n",
    "        # 創建邊索引和特徵\n",
    "        edge_index = []\n",
    "        edge_feature = []\n",
    "            \n",
    "        for _, row in window_data.iterrows():\n",
    "            artist1_idx = node_encoder.transform([row['source']])[0]\n",
    "            artist2_idx = node_encoder.transform([row['target']])[0]\n",
    "                \n",
    "            edge_index.append([artist1_idx, artist2_idx])\n",
    "                \n",
    "            # 計算邊特徵\n",
    "            views = row['views'] if 'views' in row else 0\n",
    "            likes = row['likes'] if 'likes' in row else 0\n",
    "            comments = row['comments'] if 'comments' in row else 0\n",
    "\n",
    "            # 組合特徵\n",
    "            feature = [ views, likes, comments]\n",
    "            edge_feature.append(feature)\n",
    "            \n",
    "            \n",
    "        # 轉換為張量\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_feature = torch.tensor(edge_feature, dtype=torch.float)\n",
    "\n",
    "        # 創建圖數據\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_feature)\n",
    "        test_snapshots.append(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOYNEXTDOOR_SUNGHO'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_itter.iloc[0]['source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recommendations = []\n",
    "for i, snapshot in enumerate(test_snapshots):\n",
    "    cuda_snapshot = snapshot.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embedding(cuda_snapshot.x, cuda_snapshot.edge_index, cuda_snapshot.edge_attr)\n",
    "\n",
    "    label_row = test_itter.iloc[i]\n",
    "    source = label_row['source']\n",
    "    \n",
    "    source_idx = node_encoder.transform([source])[0]\n",
    "    \n",
    "    source_embedding = embeddings[source_idx]\n",
    "    \n",
    "    similarities = F.cosine_similarity(source_embedding.unsqueeze(0), embeddings).to('cpu')\n",
    "    top_k_values, top_k_indices = torch.topk(similarities, k=11)\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx in top_k_indices[1:]:\n",
    "        rec_artist = node_encoder.inverse_transform([idx])[0]\n",
    "        recommendations.append(rec_artist)\n",
    "        \n",
    "    all_recommendations.append({\n",
    "        'source': source,\n",
    "        'label': label_row['target'],\n",
    "        'recommendations': recommendations\n",
    "    })\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 5.30 %, Hit@10: 10.62 %\n"
     ]
    }
   ],
   "source": [
    "# 計算評估指標\n",
    "true_positives = 0\n",
    "total_recommendations = 0\n",
    "reciprocal_ranks = []\n",
    "hits_at_k = 0\n",
    "    \n",
    "for recommendations in all_recommendations:\n",
    "    if recommendations['label'] in recommendations['recommendations']:\n",
    "        rank = recommendations['recommendations'].index(recommendations['label']) + 1\n",
    "        reciprocal_ranks.append(1.0 / rank)\n",
    "        if rank <= 10:\n",
    "            hits_at_k += 1\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)\n",
    "    \n",
    "    total_recommendations += len(recommendations['recommendations'])\n",
    "        \n",
    "        \n",
    "mrr = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "hit_at_k = hits_at_k / len(all_recommendations) if len(all_recommendations) > 0 else 0\n",
    "\n",
    "\n",
    "mrr_percentage = mrr * 100\n",
    "hit_at_k_percentage = hit_at_k * 100\n",
    "print(f\"MRR: {mrr_percentage:.2f} %, Hit@10: {hit_at_k_percentage:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
